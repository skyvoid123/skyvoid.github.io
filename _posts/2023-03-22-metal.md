---
layout: post
title: Metal概述
category: Graphics-API
---

**原创内容，转载请注明**

---

## RenderPipelineState

{% highlight ObjectiveC %}
MTLRenderPipelineDescriptor {
    MTLVertexDescriptor vertexDescriptor;  // 对应VertexShader使用[[stage_in]]
    MTLFunction vertexFunction; = [defaultLibrary newFunctionWithName:@"vertexShader"];  id<MTLLibrary> defaultLibrary = [MTLDevice newDefaultLibrary]; 
    MTLFunction fragmentFunction;
    MTLPrimitiveTopologyClass inputPrimitiveTopology;
    MTLRenderPipelineColorAttachmentDescriptorArray {
        MTLRenderPipelineColorAttachmentDescriptor {
            MTLPixelFormat pixelFormat;
            MTLColorWriteMask writeMask;
            ... // Blend相关配置字段;
     } colorAttachments;
    MTLPixelFormat depthAttachmentPixelFormat;
    MTLPixelFormat stencilAttachmentPixelFormat;
    
    // 以下参数详情见下面
    uint rasterSampleCount;
    bool alphaToCoverageEnabled;
    bool alphaToOneEnabled;
    bool rasterizationEnabled;
    ...
} pipelineStateDescriptor;

id<MTLRenderPipelineState> pipelineState =[MTLDevice newRenderPipelineStateWithDescriptor:pipelineStateDescriptor error:&error];
{% endhighlight %}

**Multisample的设置** <br>
If the attachment supports multisampling (that is, the attachment is a MTLTextureType2DMultisample type texture), then multiple samples can be created per pixel. To determine how fragments combine to provide pixel coverage, use the following MTLRenderPipelineDescriptor properties.
- The rasterSampleCount property determines the number of samples for each pixel. When MTLRenderCommandEncoder is created, the sampleCount for the textures for all attachments must match this sampleCount property. If the attachment cannot support multisampling, then sampleCount is 1, which is also the default value.
- If alphaToCoverageEnabled is set to YES, then the alpha channel fragment output for colorAttachments[0] is read and used to determine a coverage mask.
- If alphaToOneEnabled is set to YES, then alpha channel fragment values for colorAttachments[0] are forced to 1.0, which is the largest representable value. (Other attachments are unaffected.)

### VertexInputState

{% highlight ObjectiveC %}
MTLVertexDescriptor {
    MTLVertexBufferLayoutDescriptorArray {
        MTLVertexBufferLayoutDescriptor {
            uint stride;
            MTLVertexStepFunction stepFunction;
            uint stepRate;        
        }    
    } layout;
    MTLVertexAttributeDescriptorArray {
        MTLVertexAttributeDescriptor {
            MTLVertexFormat format;
            uint offset;
            uint bufferIndex;            
        }
    } attributes;
}
{% endhighlight %}

### DepthStencilState

{% highlight ObjectiveC %}
// 先模板测试，测试通过后深度测试
MTLDepthStencilDescriptor {
    MTLCompareFunction depthCompareFunction;
    bool depthWriteEnabled;
    MTLStencilDescriptor {
        MTLCompareFunction stencilCompareFunction;
        MTLStencilOperation stencilFailureOperation;
        MTLStencilOperation depthFailureOperation;
        MTLStencilOperation depthStencilPassOperation;
        uint32_t readMask;
        uint32_t writeMask;            
    } frontFaceStencil;
    MTLStencilDescriptor backFaceStencil;
} depthStateDesc；

id <MTLDepthStencilState> depthStencilState = [MTLDevice newDepthStencilStateWithDescriptor:depthStateDesc];
{% endhighlight %}

## Record Command Buffers

{% highlight ObjectiveC %}
MTLRenderPassDescriptor {
    MTLRenderPassColorAttachmentDescriptorArray {
        MTLRenderPassColorAttachmentDescriptor {
            MTLRenderPassAttachmentDescriptor {
                MTLTexture texture;
                uint level; uint slice; uint depthPlane;
                MTLTexture resolveTexture;
                uint resolveLevel; uint resolveSlice; uint resolveDepthPlane;  
                MTLLoadAction loadAction;
                MTLStoreAction storeAction;            
            }
            MTLClearColor clearColor;          
        }            
    } colorAttachments;
    MTLRenderPassDepthAttachmentDescriptor {
         MTLRenderPassAttachmentDescriptor {...}
         double clearDepth;   
    } depthAttachment;
    MTLRenderPassStencilAttachmentDescriptor {
        MTLRenderPassAttachmentDescriptor {...}
        uint clearStencil;    
    } stencilAttachment;
    uint defaultRasterSampleCount;
    ...
} renderPassDescriptor;

// one render pass
id<MTLRenderCommandEncoder> renderEncoder = [commandBuffer renderCommandEncoderWithDescriptor:renderPassDescriptor];
renderEncoder.label = @"MyRenderEncoder";
[renderEncoder setViewport:viewport];
[renderEncoder setScissorRect:scissorRect];
[renderEncoder setFrontFacingWinding:MTLWindingClockwise];
[renderEncoder setCullMode:MTLCullModeBack];
[renderEncoder setTriangleFillMode:MTLTriangleFillModeFill];  // or MTLTriangleFillModeLines
[renderEncoder setRenderPipelineState:pipelineState];
[renderEncoder setDepthStencilState:depthStencilState];
[renderEncoder setStencilReferenceValue:128];
[renderEncoder setVertexBuffer:vertexBuffer offset:0 atIndex:kVertexInputIndex];
[renderEncoder setFragmentTexture:texture atIndex:kFragmentTextureIndex];
[renderEncoder drawPrimitives:MTLPrimitiveTypeTriangle vertexStart:0 vertexCount:numVertices];
[renderEncoder endEncoding];

// record other renderEncoders(render passes)
...
id<MTLBlitCommandEncoder> blitEncoder = [commandBuffer blitCommandEncoder];
...
[blitEncoder endEncoding];  // 同一个CommandBuffer同一时刻只能有一个CommandEncoder在录指令，之前的CommandEncoder需endEncoding(除了MTLParallelRenderCommandEncoder)
// end recording

// 设置回调
[commandBuffer addScheduledHandler:^(id<MTLCommandBuffer>) {...}];
[commandBuffer addCompletedHandler:^(id<MTLCommandBuffer>) {...}];

// 上屏
[commandBuffer presentDrawable:view.currentDrawable];

[commandBuffer commit];
{% endhighlight %}

**Viewport: Normalized Device Coordinate To Pixel Coordinate** <br>
- NDC是一个2x2x1的长方体，近平面左下角为原点（-1, -1, 0），远平面右上角为（1, 1, 1)
- Pixel Coordinate也叫window coordinate，视口变换后（光栅化阶段）FragmentShader所在的坐标系，亦即FrameBuffer的坐标系。左上角为原点（0, 0），右下角为（fbo.width, fbo.height）
- pixel centers are offset by (0.5, 0.5). For example, the pixel at the origin has its center at (0.5, 0.5); the center of the adjacent pixel to its right is (1.5, 0.5). This is also true for textures.

**CAMetalLayer上屏** <br>
There are only a small set of drawable resources, so a long frame rendering time could temporarily exhaust those resources and cause a nextDrawable method(returns a CAMetalDrawable{id<MTLTexture> texture; CAMetalLayer *layer;} ) call to block its CPU thread until the method is completed. To avoid expensive CPU stalls, perform all per-frame operations that do not need a drawable resource before calling the nextDrawable method of a CAMetalLayer object.
[Best Practice: Hold a drawable as briefly as possible.](https://developer.apple.com/library/archive/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/Drawables.html)
> 注：默认有超时返回处理，[CAMetalLayer nextDrawable] returning nil due to 1 second timeout. Set allowsNextDrawableTimeout to keep retrying.

**Multisampled Rendering** <br>

{% highlight ObjectiveC %}
MTLTextureDescriptor *colorTexDesc = [MTLTextureDescriptor
           texture2DDescriptorWithPixelFormat:MTLPixelFormatRGBA8Unorm
           width:IMAGE_WIDTH height:IMAGE_HEIGHT mipmapped:NO];
id <MTLTexture> colorTex = [device newTextureWithDescriptor:colorTexDesc];
 
MTLTextureDescriptor *msaaTexDesc = [MTLTextureDescriptor
           texture2DDescriptorWithPixelFormat:MTLPixelFormatRGBA8Unorm
           width:IMAGE_WIDTH height:IMAGE_HEIGHT mipmapped:NO];
msaaTexDesc.textureType = MTLTextureType2DMultisample;
msaaTexDesc.sampleCount = sampleCount;  //  must be > 1
id <MTLTexture> msaaTex = [device newTextureWithDescriptor:msaaTexDesc];
 
MTLRenderPassDescriptor *renderPassDesc = [MTLRenderPassDescriptor renderPassDescriptor];
renderPassDesc.colorAttachments[0].texture = msaaTex;
renderPassDesc.colorAttachments[0].resolveTexture = colorTex;
renderPassDesc.colorAttachments[0].loadAction = MTLLoadActionClear;
renderPassDesc.colorAttachments[0].storeAction = MTLStoreActionMultisampleResolve;
renderPassDesc.colorAttachments[0].clearColor = MTLClearColorMake(0.0,1.0,0.0,1.0);
{% endhighlight %}


**Command queues** are thread-safe and allow multiple active command buffers to be encoded simultaneously
**Command Buffers执行顺序：** <br>
- The enqueue method reserves a place for the command buffer on the command queue, but does not commit the command buffer for execution. When this command buffer is eventually committed, it is executed after any previously enqueued command buffers within the associated command queue.
- The commit method causes the command buffer to be executed as soon as possible, but after any previously enqueued command buffers in the same command queue are committed. If the command buffer has not previously been enqueued, commit makes an implied enqueue call.

### Encoding a Single Rendering Pass Using Multiple Threads

{% highlight ObjectiveC %}
MTLRenderPassDescriptor *renderPassDesc 
                     = [MTLRenderPassDescriptor renderPassDescriptor];
renderPassDesc.colorAttachments[0].texture = currentTexture;
renderPassDesc.colorAttachments[0].loadAction = MTLLoadActionClear;
renderPassDesc.colorAttachments[0].clearColor = MTLClearColorMake(0.0,0.0,0.0,1.0);

id <MTLParallelRenderCommandEncoder> parallelRCE = [commandBuffer 
                     parallelRenderCommandEncoderWithDescriptor:renderPassDesc];
id <MTLRenderCommandEncoder> rCE1 = [parallelRCE renderCommandEncoder];
id <MTLRenderCommandEncoder> rCE2 = [parallelRCE renderCommandEncoder];
id <MTLRenderCommandEncoder> rCE3 = [parallelRCE renderCommandEncoder];

//  not shown: rCE1, rCE2, and rCE3 call methods to encode graphics commands
//
//  rCE1 commands are processed first, because it was created first even though rCE2 and rCE3 end earlier than rCE1
[rCE2 endEncoding];
[rCE3 endEncoding];
[rCE1 endEncoding];

//  all MTLRenderCommandEncoders must end before MTLParallelRenderCommandEncoder
[parallelRCE endEncoding];
{% endhighlight %}

## Resource Objects: Buffers and Textures

{% highlight ObjectiveC %}
MTLDevice newBufferWithLength:options:(MTLResourceStorageModeShared/MTLResourceStorageModePrivate/MTLResourceStorageModeManaged)
MTLDevice newBufferWithBytes:length:options:
MTLDevice newTextureWithDescriptor:(MTLTextureDescriptor)

MTLTextureDescriptor {
    MTLTextureType textureType;  // MTLTextureType1D/MTLTextureType2D ...
    MTLPixelFormat pixelFormat;  // MTLPixelFormatRGBA8Unorm ...
    NSUInteger width; NSUInteger height; NSUInteger depth;
    NSUInteger mipmapLevelCount;
    NSUInteger sampleCount;
    NSUInteger arrayLength;
    MTLTextureUsage usage;  // MTLTextureUsageShaderRead/MTLTextureUsageShaderWrite/MTLTextureUsageRenderTarget/MTLTextureUsagePixelFormatView
    MTLCPUCacheMode cpuCacheMode;  // 默认值MTLCPUCacheModeDefaultCache/MTLCPUCacheModeWriteCombined
    MTLStorageMode storageMode;  // MTLStorageModeShared/MTLStorageModePrivate/MTLStorageModeMemoryless/MTLStorageModeManaged
    MTLHazardTrackingMode hazardTrackingMode;  // 默认值MTLHazardTrackingModeDefault/MTLHazardTrackingModeUntracked/MTLHazardTrackingModeTracked
    MTLResourceOptions resourceOptions;  // a packed set of the storageMode, cpuCacheMode and hazardTrackingMode properties
}

// 从CPU端数据加载纹理
[tex replaceRegion:MTLRegionMake2D(0,0,width,height)
    mipmapLevel:0 slice:0 withBytes:textureData
    bytesPerRow:myRowBytes bytesPerImage:myImageBytes];
{% endhighlight %}

**MTLHazardTrackingMode:**<br>
- For resources created from the device, MTLHazardTrackingModeDefault is treated as MTLHazardTrackingModeTracked.
- For resources created on a heap, MTLHazardTrackingModeDefault is treated as the hazardTrackingMode of the heap itself.
- In either case, it is possible to opt-out（退出） of hazard tracking by setting MTLHazardTrackingModeUntracked.
- It is not possible to opt-in（加入） to hazard tracking on a heap that itself is not hazard tracked.
- For optimal performance, perform hazard tracking manually through MTLFence or MTLEvent instead.

### Sampler State

{% highlight ObjectiveC %}
// create MTLSamplerDescriptor
MTLSamplerDescriptor *desc = [[MTLSamplerDescriptor alloc] init];
desc.minFilter = MTLSamplerMinMagFilterLinear;
desc.magFilter = MTLSamplerMinMagFilterLinear;
desc.sAddressMode = MTLSamplerAddressModeRepeat;
desc.tAddressMode = MTLSamplerAddressModeRepeat;
//  all properties below have default values
desc.mipFilter        = MTLSamplerMipFilterNotMipmapped;
desc.maxAnisotropy    = 1U;
desc.normalizedCoords = YES;
desc.lodMinClamp      = 0.0f;
desc.lodMaxClamp      = FLT_MAX;
// create MTLSamplerState
id <MTLSamplerState> sampler = [device newSamplerStateWithDescriptor:desc];
{% endhighlight %}

### Argument Buffers
Argument buffer是一个MTLBuffer，是对传入Shader参数的打包封装，可以包括内置类型（half/float/half4/float4x4/buffer*/texture/sampler/struct/array）。
对于每帧不变的资源，将其封装至一个argument buffer内，可以避免为每一参数一一进行资源状态跟踪和argument table索引（统一管理，避免分别管理，以减少CPU开销）。
Argument buffer可以扩大Shader对于参数数量的限制（不使用argument buffer情况下，buffer/texture最多31个，sampler最多16个）

{% highlight ObjectiveC %}
// CPU端代码
// 初始化阶段
id <MTLFunction> fragmentFunction = [defaultLibrary newFunctionWithName:@"fragmentShader"];
id <MTLArgumentEncoder> argumentEncoder = [fragmentFunction newArgumentEncoderWithBufferIndex:kFragmentBufferIndexArguments];
NSUInteger argumentBufferLength = argumentEncoder.encodedLength;
_fragmentShaderArgumentBuffer = [_device newBufferWithLength:argumentBufferLength options:0];
_fragmentShaderArgumentBuffer.label = @"Argument Buffer";
[argumentEncoder setArgumentBuffer:_fragmentShaderArgumentBuffer offset:0];  // id<MTLBuffer> _fragmentShaderArgumentBuffer;

[argumentEncoder setTexture:_texture atIndex:kArgumentBufferTextureID];
[argumentEncoder setSamplerState:_sampler atIndex:kArgumentBufferSamplerID];
[argumentEncoder setBuffer:_buffer offset:0 atIndex:kArgumentBufferBufferID];

uint32_t *numElementsAddress = [argumentEncoder constantDataAtIndex:kArgumentBufferConstantID];
*numElementsAddress = bufferElements;  // const uint16_t bufferElements = 256;

// 每帧渲染阶段
...
// Indicate to Metal that these resources will be accessed by the GPU，and therefore must be mapped to the GPU's address space
[renderEncoder useResource:_texture usage:MTLResourceUsageSample];
[renderEncoder useResource:_buffer usage:MTLResourceUsageRead];
[renderEncoder setFragmentBuffer:_fragmentShaderArgumentBuffer
                          offset:0
                         atIndex:kFragmentBufferIndexArguments];
...

// Shader代码
typedef struct FragmentShaderArguments {
    texture2d<half> exampleTexture  [[ id(kArgumentBufferTextureID)  ]];
    sampler         exampleSampler  [[ id(kArgumentBufferSamplerID)  ]];
    device float   *exampleBuffer   [[ id(kArgumentBufferBufferID)   ]];
    uint32_t        exampleConstant [[ id(kArgumentBufferConstantID) ]];
} FragmentShaderArguments;

fragment float4
fragmentShader(       RasterizerData            in                 [[ stage_in ]],
               device FragmentShaderArguments & fragmentShaderArgs [[ buffer(kFragmentBufferIndexArguments) ]])
{
    // Get the sampler encoded in the argument buffer
    sampler exampleSampler = fragmentShaderArgs.exampleSampler;
    // Sample the texture encoded in the argument buffer
    half4 textureSample = fragmentShaderArgs.exampleTexture.sample(exampleSampler, in.texCoord);
    // Use the fragment position and the constant encoded in the argument buffer to calculate an array index
    uint32_t index = (uint32_t)in.position.x % fragmentShaderArgs.exampleConstant;
    // Index into the buffer encoded in the argument buffer
    float colorScale = fragmentShaderArgs.exampleBuffer[index];
    // Add sample and color values together and return the result
    return float4((1.0-textureSample.w) * colorScale * in.color + textureSample);
}
{% endhighlight %}

### Resource Heaps

{% highlight ObjectiveC %}
// Calculate the size and alignment of each resource
MTLSizeAndAlign albedoSizeAndAlign = [_device heapTextureSizeAndAlignWithDescriptor:_albedoDescriptor];
MTLSizeAndAlign normalSizeAndAlign = [_device heapTextureSizeAndAlignWithDescriptor:_normalDescriptor];
MTLSizeAndAlign glossSizeAndAlign  = [_device heapTextureSizeAndAlignWithDescriptor:_glossDescriptor];
 
// Calculate a heap size that satisfies the size requirements of all three resources
NSUInteger heapSize = albedoSizeAndAlign.size + normalSizeAndAlign.size + glossSizeAndAlign.size;
 
// Create a heap descriptor
MTLHeapDescriptor* heapDescriptor = [MTLHeapDescriptor new];
heapDescriptor.cpuCacheMode = MTLCPUCacheModeDefaultCache;
heapDescriptor.storageMode = MTLStorageModePrivate;
heapDescriptor.size = heapSize;
 
// Create a heap
id <MTLHeap> heap = [_device newHeapWithDescriptor:heapDescriptor];
 
// Create sub-allocated resources from the heap
id <MTLTexture> albedoTexture = [_heap newTextureWithDescriptor:_albedoDescriptor];
id <MTLTexture> normalTexture = [_heap newTextureWithDescriptor:_normalDescriptor];
id <MTLTexture> glossTexture  = [_heap newTextureWithDescriptor:_glossDescriptor];
{% endhighlight %}

> Note: Heaps are thread-safe, but you may still need to synchronize heaps at the app level to ensure aliasing is set up as expected.
Command dependencies between sub-allocated resources is not automatic; manual tracking must be explicitly declared and managed via the MTLFence API.

### Resource Synchronization
Your app is responsible for manually synchronizing the resources that Metal doesn’t track. You can synchronize resources with these mechanisms, which are in ascending scope order:
- Memory barriers
- Memory fences
- Metal events
- Metal shared events

A memory barrier forces any subsequent commands to wait until the previous commands in a pass (such as a render or compute pass) finishes using memory. You can limit the scope of a memory barrier to a buffer, texture, render attachment, or a combination.
An MTLFence synchronizes access to one or more resources across different passes within a command buffer( or between different command buffers). Use fences to specify any inter-pass resource dependencies within the same command buffer.
An MTLEvent synchronizes access to one or more resources on a single MTLDevice. You can tell the GPU to pause work until another command signals an event. See Synchronizing Events Within a Single Device for more information.
An MTLSharedEvent synchronizes access to one or more resources with other Metal device instances or with the CPU. Shared events are similar to a regular event, but with a larger scope that goes beyond a single GPU to include the CPU and other GPUs. See Synchronizing Events Between a GPU and the CPU and Synchronizing Events Across Multiple Devices or Processes for more information.

#### Fence
Drivers may wait on fences at the beginning of a command encoder, and drivers may delay fence updates until the end of the command encoder. Therefore, you are not allowed to first update and then wait on the same fence in the same command encoder (however, you are allowed to first wait and then update). Producer-consumer relationships must be split across different command encoders.
A fence can wait for workloads that have already begun, but it can’t wait for future workloads.

> 自己的理解：waitForFence: GPU会按照CommandBuffers的入队顺序，以及CommandEncoders的顺序，来执行指令（保证execution dependency，但不保证memory dependency），即updateFence: 先通知激活排在最前面的waitForFence:

{% highlight ObjectiveC %}
// Fence示例
id <MTLFence> fence = [_device newFence];
id <MTLCommandBuffer> commandBuffer = [_commandQueue commandBuffer];
 
// Producer
id <MTLRenderCommandEncoder> renderCommandEncoder = [commandBuffer renderCommandEncoderWithDescriptor:_descriptor];
/* Draw using resources associated with 'fence' */
[renderCommandEncoder updateFence:fence afterStages:MTLRenderStageFragment];
[renderCommandEncoder endEncoding];
 
// Consumer
id <MTLComputeCommandEncoder> computeCommandEncoder = [commandBuffer computeCommandEncoder];
[computeCommandEncoder waitForFence:fence];
/* Dispatch using resources associated with 'fence' */
[computeCommandEncoder endEncoding];
 
[commandBuffer commit];
{% endhighlight %}

{% highlight ObjectiveC %}
// 跨CommandBuffers使用Fence，Fence不能控制CommandQueue中CommandBuffers之间的时序，仍需手动控制CommandBuffers的入队顺序
id <MTLFence> fence = [_device newFence];
id <MTLCommandBuffer> commandBuffer0 = [_commandQueue0 commandBuffer];
id <MTLCommandBuffer> commandBuffer1 = [_commandQueue1 commandBuffer];
 
// Producer
id <MTLRenderCommandEncoder> renderCommandEncoder = [commandBuffer0 renderCommandEncoderWithDescriptor:_descriptor];
/* Draw using resources associated with 'fence' */
[renderCommandEncoder updateFence:fence afterStages:MTLRenderStageFragment];
[renderCommandEncoder endEncoding];
 
// Consumer
id <MTLComputeCommandEncoder> computeCommandEncoder = [commandBuffer1 computeCommandEncoder];
[computeCommandEncoder waitForFence:fence];
/* Dispatch using resources associated with 'fence' */
[computeCommandEncoder endEncoding];
 
// Ensure 'commandBuffer0' is scheduled before 'commandBuffer1'
[commandBuffer0 addScheduledHandler:^(id <MTLCommandBuffer>) {
    [commandBuffer1 commit];
}];
[commandBuffer0 commit];
{% endhighlight %}

#### Event
Unlike fences, events can wait for workloads that have already begun, as well as future workloads. 
Additionally, events are specified outside command encoder boundaries, not between the encoded commands of a command encoder. Because the event synchronization mechanism is implemented in the command buffer scheduler, events block workloads at the command buffer level within the GPU. Therefore, command buffers on one queue can execute while a command buffer on another queue is blocked by an event.
encodeSignalEvent:value: 和 encodeWaitForEvent:value: （signal_value >= wait_value，则执行）需在CommandEncoder外部调用，不能在CommandEncoder内部调用（MTLFence则需要在CommandEncoder内部调用）

<br>

**GPU与CPU之间的同步：MTLSharedEvent**

![img](/assets/metal-event.png)

{% highlight ObjectiveC %}
// GPU与CPU之间的同步：MTLSharedEvent
- (void)setupGPUCPUEvent
{
    // Shareable event
    _sharedEvent = [_device newSharedEvent];
    
    // Shareable event listener
    dispatch_queue_t myQueue = dispatch_queue_create("com.example.apple-samplecode.MyQueue", NULL);
    _sharedEventListener = [[MTLSharedEventListener alloc] initWithDispatchQueue:myQueue];
}

- (void)renderFrame
{
    // Register CPU work
    [_sharedEvent notifyListener:_sharedEventListener
                         atValue:2
                           block:^(id<MTLSharedEvent> sharedEvent, uint64_t value) {
        /* Do CPU work */
        sharedEvent.signaledValue = 3;
    }];
    
    // Encode GPU work
    id<MTLCommandBuffer> commandBuffer = [_commandQueue commandBuffer];
    /* Encode GPU work part 1 */
    [commandBuffer encodeSignalEvent:_sharedEvent value:1];
    /* Encode GPU work part 2 */
    [commandBuffer encodeSignalEvent:_sharedEvent value:2];
    [commandBuffer encodeWaitForEvent:_sharedEvent value:3];
    /* Encode GPU work part 3 */
    [commandBuffer commit];
}
{% endhighlight %}

#### Semaphore
利用addCompletedHandler:可实现CPU与GPU直接的同步

{% highlight ObjectiveC %}
dispatch_semaphore_t _inFlightSemaphore = dispatch_semaphore_create(kMaxFramesInFlight);

// 每帧渲染阶段
dispatch_semaphore_wait(_inFlightSemaphore, DISPATCH_TIME_FOREVER);
...
__block dispatch_semaphore_t block_semaphore = _inFlightSemaphore;
[commandBuffer addCompletedHandler:^(id<MTLCommandBuffer> buffer) {
     dispatch_semaphore_signal(block_semaphore);
 }];
[commandBuffer commit];
{% endhighlight %}

## Raster Order Groups
Raster order groups allow Metal 2 apps to precisely control the order of parallel fragment shader threads accessing the same pixel coordinates.
On a traditional GPU, a thread responsible for a secondary light must wait for access until prior threads complete before it can begin. This wait forces the threads to run serially, even if the accesses don’t conflict with each other.

![img](/assets/Raster-Order-Groups-1.png)


You can use multiple order groups to run the nonconflicting reads concurrently by:
1. Adding the three G-buffer fields — albedo, normal, and depth — to the first group
2. Adding the accumulated lighting result to the second group
Apple GPUs can order the two groups separately so that outstanding writes into the second group don’t impede the reads from the first group.

![img](/assets/Raster-Order-Groups-2.png)

{% highlight ObjectiveC %}
// Shader代码
// Raster order group definitions
#define AAPLLightingROG  0  // 同group内会同步，避免读写冲突
#define AAPLGBufferROG   1  // 不同group之间无读写冲突(需用户正确指定)

// G-buffer outputs using Raster Order Groups
struct GBufferData
{
    half4 lighting        [[color(AAPLRenderTargetLighting), raster_order_group(AAPLLightingROG)]];
    half4 albedo_specular [[color(AAPLRenderTargetAlbedo),   raster_order_group(AAPLGBufferROG)]];
    half4 normal_shadow   [[color(AAPLRenderTargetNormal),   raster_order_group(AAPLGBufferROG)]];
    float depth           [[color(AAPLRenderTargetDepth),    raster_order_group(AAPLGBufferROG)]];
};
// Final buffer outputs using Raster Order Groups
struct AccumLightBuffer
{
    half4 lighting [[color(AAPLRenderTargetLighting), raster_order_group(AAPLLightingROG)]];
};

fragment GBufferData gbuffer_fragment(...) 
{
   // Fill in on-chip geometry buffer data
    GBufferData gBuffer;
    gBuffer.albedo_specular = ...;
    gBuffer.normal_shadow = ...;
    gBuffer.depth = ...;
    return gBuffer;
}

fragment AccumLightBuffer deferred_directional_lighting_fragment(...)
{
    AccumLightBuffer output;
    output.lighting = ...;
    return output;
}

fragment AccumLightBuffer deferred_point_lighting_fragment(...)
{
    AccumLightBuffer output;
    output.lighting = ...;
    return output;
}
{% endhighlight %}

## Indirect Command Encoding
Indirect command buffers (ICB)可重复使用（而正常的command buffers是一次性的，commit后不能再使用）

### Encoding Indirect Command Buffers on the CPU

{% highlight ObjectiveC %}
//  初始化阶段
// Needed for this pipeline state to be used in indirect command buffers.
pipelineStateDescriptor.supportIndirectCommandBuffers = TRUE;
...
MTLIndirectCommandBufferDescriptor* icbDescriptor = [MTLIndirectCommandBufferDescriptor new];

// Indicate that the only draw commands will be standard (non-indexed) draw commands.
icbDescriptor.commandTypes = MTLIndirectCommandTypeDraw;

// Indicate that buffers will be set for each command IN the indirect command buffer.
icbDescriptor.inheritBuffers = NO;

// Indicate that a max of 3 buffers will be set for each command.
icbDescriptor.maxVertexBufferBindCount = 3;
icbDescriptor.maxFragmentBufferBindCount = 0;

#if defined TARGET_MACOS || defined(__IPHONE_13_0)
// Indicate that the render pipeline state object will be set in the render command encoder
// (not by the indirect command buffer).
// On iOS, this property only exists on iOS 13 and later.  It defaults to YES in earlier
// versions
if (@available(iOS 13.0, *)) {
    icbDescriptor.inheritPipelineState = YES;
}
#endif
// id<MTLIndirectCommandBuffer> _indirectCommandBuffer;
_indirectCommandBuffer = [_device newIndirectCommandBufferWithDescriptor:icbDescriptor
                                                         maxCommandCount:AAPLNumObjects
                                                                 options:0];

//  Encode a draw command for each object drawn in the indirect command buffer.
for (int objIndex = 0; objIndex < AAPLNumObjects; objIndex++)
{
    id<MTLIndirectRenderCommand> ICBCommand = [_indirectCommandBuffer indirectRenderCommandAtIndex:objIndex];

    [ICBCommand setVertexBuffer:_vertexBuffer[objIndex]
                         offset:0
                        atIndex:AAPLVertexBufferIndexVertices];

    [ICBCommand setVertexBuffer:_indirectFrameStateBuffer
                         offset:0
                        atIndex:AAPLVertexBufferIndexFrameState];

    [ICBCommand setVertexBuffer:_objectParameters
                         offset:0
                        atIndex:AAPLVertexBufferIndexObjectParams];

    const NSUInteger vertexCount = _vertexBuffer[objIndex].length/sizeof(AAPLVertex);

    [ICBCommand drawPrimitives:MTLPrimitiveTypeTriangle
                   vertexStart:0
                   vertexCount:vertexCount
                 instanceCount:1
                  baseInstance:objIndex];
}

// 每帧渲染阶段
// ICB录好指令后不能再修改(重新绑定buffer或texture)，数据更新需要通过blit把更新的数据拷贝到ICB已绑定的buffer或texture中
// Update a single buffer in your dynamic buffer array on the CPU
_frameNumber++;
_inFlightIndex = _frameNumber % AAPLMaxFramesInFlight;
AAPLFrameState * frameState = _frameStateBuffer[_inFlightIndex].contents;
// Blit the CPU-side buffer set to the location that’s accessible to the ICB
id<MTLBlitCommandEncoder> blitEncoder = [commandBuffer blitCommandEncoder];
[blitEncoder copyFromBuffer:_frameStateBuffer[_inFlightIndex] sourceOffset:0
                   toBuffer:_indirectFrameStateBuffer destinationOffset:0  // ICB一直绑定着_indirectFrameStateBuffer
                       size:_indirectFrameStateBuffer.length];
[blitEncoder endEncoding];
...
// Make a useResource call for each buffer needed by the indirect command buffer.
for (int i = 0; i < AAPLNumObjects; i++) {    
    [renderEncoder useResource:_vertexBuffer[i] usage:MTLResourceUsageRead];
}
[renderEncoder useResource:_objectParameters usage:MTLResourceUsageRead];
[renderEncoder useResource:_indirectFrameStateBuffer usage:MTLResourceUsageRead];
// Draw everything in the indirect command buffer.
[renderEncoder executeCommandsInBuffer:_indirectCommandBuffer withRange:NSMakeRange(0, AAPLNumObjects)];
[renderEncoder endEncoding];
{% endhighlight %}

### Encoding Indirect Command Buffers on the GPU

{% highlight ObjectiveC %}
// CPU端代码
// 初始化阶段
// Create indirect command buffer using private storage mode; since only the GPU will
// write to and read from the indirect command buffer, the CPU never needs to access the memory
_indirectCommandBuffer = [_device newIndirectCommandBufferWithDescriptor:icbDescriptor  // icbDescriptor的创建同上面的CPU端ICB
                                                         maxCommandCount:AAPLNumObjects
                                                                 options:MTLResourceStorageModePrivate];
// id<MTLFunction> GPUCommandEncodingKernel = [defaultLibrary newFunctionWithName:@"cullMeshesAndEncodeCommands"];
id<MTLArgumentEncoder> argumentEncoder = [GPUCommandEncodingKernel newArgumentEncoderWithBufferIndex:AAPLKernelBufferIndexCommandBufferContainer];

_icbArgumentBuffer = [_device newBufferWithLength:argumentEncoder.encodedLength
                                          options:MTLResourceStorageModeShared];

[argumentEncoder setArgumentBuffer:_icbArgumentBuffer offset:0];

[argumentEncoder setIndirectCommandBuffer:_indirectCommandBuffer
                                  atIndex:AAPLArgumentBufferIDCommandBuffer];

// 每帧渲染阶段                                                     
// Encode command to reset the indirect command buffer
{
    id<MTLBlitCommandEncoder> resetBlitEncoder = [commandBuffer blitCommandEncoder];
    [resetBlitEncoder resetCommandsInBuffer:_indirectCommandBuffer
                                  withRange:NSMakeRange(0, AAPLNumObjects)];
    [resetBlitEncoder endEncoding];
}
// Encode commands to determine visibility of objects using a compute kernel
{
    id<MTLComputeCommandEncoder> computeEncoder = [commandBuffer computeCommandEncoder];
    ...
    [computeEncoder setBuffer:_icbArgumentBuffer offset:0 atIndex:AAPLKernelBufferIndexCommandBufferContainer];
    
    // Call useResource on '_indirectCommandBuffer' which indicates to Metal that the kernel will
    // access '_indirectCommandBuffer'.  It is necessary because the app cannot directly set
    // '_indirectCommandBuffer' in 'computeEncoder', but, rather, must pass it to the kernel via
    // an argument buffer which indirectly contains '_indirectCommandBuffer'.
    [computeEncoder useResource:_indirectCommandBuffer usage:MTLResourceUsageWrite];
    
    [computeEncoder dispatchThreads:MTLSizeMake(AAPLNumObjects, 1, 1)
                threadsPerThreadgroup:MTLSizeMake(threadExecutionWidth, 1, 1)];
    
    [computeEncoder endEncoding];
}

// Encode command to optimize the indirect command buffer after encoding
{
    id<MTLBlitCommandEncoder> optimizeBlitEncoder = [commandBuffer blitCommandEncoder];
    [optimizeBlitEncoder optimizeIndirectCommandBuffer:_indirectCommandBuffer
                                             withRange:NSMakeRange(0, AAPLNumObjects)];
    [optimizeBlitEncoder endEncoding];
}

// Encode command to draw the drawable
{
    id <MTLRenderCommandEncoder> renderEncoder = [commandBuffer renderCommandEncoderWithDescriptor:renderPassDescriptor];
    ...
    // Make a useResource call for each buffer needed by the indirect command buffer
    [renderEncoder useResource:_vertexBuffer usage:MTLResourceUsageRead];
    [renderEncoder useResource:_objectParameters usage:MTLResourceUsageRead];
    [renderEncoder useResource:_frameStateBuffer[_inFlightIndex] usage:MTLResourceUsageRead];

    // Draw everything in the indirect command buffer
    [renderEncoder executeCommandsInBuffer:_indirectCommandBuffer withRange:NSMakeRange(0, AAPLNumObjects)];

    [renderEncoder endEncoding];
}                                  
{% endhighlight %}

{% highlight ObjectiveC %}
// Shader代码
// This is the argument buffer that contains the ICB.
typedef struct ICBContainer {
    command_buffer commandBuffer [[ id(AAPLArgumentBufferIDCommandBuffer) ]];
} ICBContainer;

// Check whether the object at 'objectIndex' is visible and set draw parameters if so.
// Otherwise, reset the command so that nothing is done.
kernel void cullMeshesAndEncodeCommands(uint                          objectIndex   [[ thread_position_in_grid ]],
                                        constant AAPLFrameState      *frame_state   [[ buffer(AAPLKernelBufferIndexFrameState) ]],
                                        device AAPLObjectPerameters  *object_params [[ buffer(AAPLKernelBufferIndexObjectParams)]],
                                        device AAPLVertex            *vertices      [[ buffer(AAPLKernelBufferIndexVertices) ]],
                                        device ICBContainer          *icb_container [[ buffer(AAPLKernelBufferIndexCommandBufferContainer) ]]) {
    ...
    // Get indirect render commnd object from the indirect command buffer given the object's unique
    // index to set parameters for drawing (or not drawing) the object.
    render_command cmd(icb_container->commandBuffer, objectIndex);

    if(visible) {
        // Set the buffers and add a draw command.
        cmd.set_vertex_buffer(frame_state, AAPLVertexBufferIndexFrameState);
        cmd.set_vertex_buffer(object_params, AAPLVertexBufferIndexObjectParams);
        cmd.set_vertex_buffer(vertices, AAPLVertexBufferIndexVertices);

        cmd.draw_primitives(primitive_type::triangle,
                            object_params[objectIndex].startVertex,
                            object_params[objectIndex].numVertices, 1,
                            objectIndex);
    }
    
    // If the object is not visible, no draw command will be set since so long as the app has reset
    // the indirect command buffer commands with a blit encoder before encoding the draw.
}

vertex RasterizerData
vertexShader(uint                     vertexID      [[ vertex_id ]],
             uint                     objectIndex   [[ instance_id ]],
             const device AAPLVertex* vertices      [[ buffer(AAPLVertexBufferIndexVertices) ]],
             const device AAPLObjectPerameters* object_params [[ buffer(AAPLVertexBufferIndexObjectParams) ]],
             constant AAPLFrameState* frame_state   [[ buffer(AAPLVertexBufferIndexFrameState) ]]) {
...
}
{% endhighlight %}

## Shader
### Shader反射
详情见[Determining Function Details at Runtime章节](https://developer.apple.com/library/archive/documentation/Miscellaneous/Conceptual/MetalProgrammingGuide/Prog-Func/Prog-Func.html) 

### Shader Function Specialization

**Function constants can be used to:**
1. Control which function code paths get compiled
2. Specify optional arguments of a function
3. Specify optional elements of a struct declared with the [[ stage_in ]] qualifier

{% highlight ObjectiveC %}
// in shader
constant bool offset_defined [[function_constant(0)]]; 
constant bool color_defined [[function_constant(1)]];                                            
constant bool hasInputTexture [[function_constant(3)]];                                    

struct VertexOutput {
    float4 position [[position]];
    float4 color;
};

struct VertexInput {
    float4 position [[attribute(0)]];
    float4 offset [[attribute(1), function_constant(offset_defined)]];
    float4 color [[attribute(2), function_constant(color_defined)]];
    float2 tex_coord [[attribute(3), function_constant(hasInputTexture)]];
};

vertex VertexOutput myVertex(VertexInput vIn [[stage_in]],                                                 
                             texture2d<float> inTexture [[texture(0), function_constant(hasInputTexture)]]) {
    VertexOutput vOut;
    vOut.position = vIn.position; 
    if (offset_defined) vOut.position += vIn.offset;
    if (color_defined) vOut.color = vIn.color;
    else vOut.color = float4(0.0f);
    if (hasInputTexture) vOut.color = inTexture.sample(linearSampler, vIn.tex_coord);
    return vOut;
}
{% endhighlight %}

{% highlight ObjectiveC %}
// in cpu
const bool offsetDefined = true;  // 可运行时通过计算得出
const bool colorDefined = true;  // 可运行时通过计算得出
const bool hasInputTexture = false;  // 可运行时通过计算得出
MTLFunctionConstantValues* constantValues = [MTLFunctionConstantValues new];
[constantValues setConstantValue:&offsetDefined type:MTLDataTypeBool atIndex:0];
[constantValues setConstantValue:&colorDefined type:MTLDataTypeBool atIndex:1];
[constantValues setConstantValue:&hasInputTexture type:MTLDataTypeBool atIndex:3];

id<MTLFunction> vertexFunction = [mtlLibrary newFunctionWithName:@"myVertex" constantValues:constantValues error:&err];
{% endhighlight %}
